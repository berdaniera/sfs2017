{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DO_mgL', 'Discharge_m3s', 'SpecCond_uScm', 'WaterTemp_C', 'pH']\n"
     ]
    }
   ],
   "source": [
    "#x = pd.read_csv(\"CT_Farmington.csv\")\n",
    "x = pd.read_csv(\"WI_BlackEarthCreek.csv\")\n",
    "xx = x.copy()[[c for c in x.columns if c not in ['region','site']]] \\\n",
    "    .set_index(pd.to_datetime(x['DateTime_UTC'])).resample(\"15Min\").mean()\n",
    "xx = xx[xx.index>=\"2010-10-02\"]\n",
    "variables = xx.columns.tolist()\n",
    "print variables\n",
    "\n",
    "# Create flags, assign first value to be flagged\n",
    "xx['flag'] = 0\n",
    "\n",
    "var = 'DO_mgL' # variable to add error\n",
    "\n",
    "frac = 0.20 # fraction of maximum error\n",
    "dayn = 30 # das of training data\n",
    "obsn = 14 # days of testing data\n",
    "outall = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up k-folds\n",
    "# break into 180 day chunks\n",
    "alldays = np.sort(list(set(xx.index.date)))\n",
    "breaks = np.array_split(alldays, int(len(alldays)/180))\n",
    "\n",
    "# fraction errors to introduce\n",
    "fracs = [0.05,0.1,0.15,0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for frac in fracs:\n",
    "    output = pd.DataFrame(columns=['days','accuracy'])\n",
    "    print frac\n",
    "\n",
    "    for k in xrange(len(breaks)):\n",
    "        xk = xx.copy().iloc[(xx.index.date > breaks[k][0]) & (xx.index.date <= breaks[k][-1])]\n",
    "        print k\n",
    "        \n",
    "        drange = xrange(7,180,30)\n",
    "        for dayn in drange:\n",
    "            train = xk.copy()[xk.index <= xk.index[0]+timedelta(days=dayn)]\n",
    "            test = xk.copy()[(xk.index > xk.index[0]+timedelta(days=dayn)) & (xk.index <= xk.index[0]+timedelta(days=dayn+obsn))]\n",
    "\n",
    "            #clf = svm.LinearSVC(C=1e5)\n",
    "            xtrain = train.dropna()\n",
    "            if dayn==drange[0]:\n",
    "                clf = svm.SVC(C=1000)\n",
    "                xtrain.loc[xtrain.index[0],'flag'] = 1\n",
    "            else:\n",
    "                clf = svm.NuSVC(nu=0.05)\n",
    "            xsvm = xtrain.as_matrix(variables)\n",
    "            scaler = StandardScaler().fit(xsvm)\n",
    "            clf.fit(scaler.transform(xsvm), xtrain.flag)\n",
    "\n",
    "            # random error assignment - half of two week sample\n",
    "            xtest = test.copy().dropna()\n",
    "            werr = np.random.choice(range(0, len(xtest)), len(xtest)/2, False)\n",
    "            xtest.iloc[werr,xtest.columns==var] = xtest.iloc[werr,xtest.columns==var]*(1-frac)\n",
    "            xtest['actual'] = 0\n",
    "            xtest.iloc[werr,xtest.columns=='actual'] = 1 # which have error added\n",
    "\n",
    "            xpred = xtest.as_matrix(variables)\n",
    "            xtest['pred'] = clf.predict(scaler.transform(xpred)).tolist() # -1 are anomalies\n",
    "\n",
    "            xk.loc[xtest.index, 'flag'] = xtest['actual'] #replace error data, perfect detection\n",
    "            xk.loc[xtest.index, var] = xtest[var] # replace variable data for update\n",
    "\n",
    "            #print str(dayn)+\": \"+str(len(xtest))+\"/\"+str(len(xtrain))\n",
    "            outacc = metrics.accuracy_score(xtest['actual'], xtest['pred'])\n",
    "            output = pd.concat([output, pd.DataFrame([[dayn,outacc]], columns=['days','accuracy'])])\n",
    "\n",
    "    output['frac'] = frac\n",
    "    outall = pd.concat([outall, output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outall.to_csv(\"error_checking_output.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
